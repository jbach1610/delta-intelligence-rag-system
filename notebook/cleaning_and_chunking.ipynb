{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1cab5faf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pdfplumber\n",
    "from pdf2image import convert_from_path\n",
    "import pytesseract\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a36b6378",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_colwidth\", 200)\n",
    "\n",
    "company_name = \"delta\"\n",
    "os.makedirs(\"output\", exist_ok=True)\n",
    "os.makedirs(f\"data/{company_name}\", exist_ok=True)\n",
    "\n",
    "\n",
    "input_files = {\n",
    "    # \"annual_report_2020\": \"input/10K Report 2020.pdf\",\n",
    "    # \"annual_report_2021\": \"input/10K Report 2021.pdf\",\n",
    "    # \"annual_report_2022\": \"input/10K Report 2022.pdf\",\n",
    "    # \"annual_report_2023\": \"input/10K Report 2023.pdf\",\n",
    "    \"annual_report_2024\": \"input/10K Report 2024.pdf\",\n",
    "    # \"esg_report_2020\": \"input/ESG Report 2020.pdf\",\n",
    "    # \"esg_report_2021\": \"input/ESG Report 2021.pdf\",\n",
    "    # \"esg_report_2022\": \"input/ESG Report 2022.pdf\",\n",
    "    # \"esg_report_2023\": \"input/ESG Report 2023.pdf\",\n",
    "    \"esg_report_2024\": \"input/ESG Report 2024.pdf\",\n",
    "    \"major_holders\": \"input/Major Holders Summary.pdf\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8e5fbc8",
   "metadata": {},
   "source": [
    "# <span style=\"color: aquamarine;\">I. PDF Extraction and Cleaning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "612237f3",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Clean Text</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "719c73ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(text):\n",
    "    if not text:\n",
    "        return \"\"\n",
    "\n",
    "    text = re.sub(r\"[ \\t]+\", \" \", text) #Replace multiple spaces/tabs with a single space\n",
    "    text = re.sub(r\"\\n\\s*\\n\\s*\\n+\", \"\\n\\n\", text) #Replace multiple blank lines into 1 blank line\n",
    "    text = text.replace(\"\\x00\", \"\") #Remove NULL characters\n",
    "    text = text.replace(\"\\uf0b7\", \"•\") #Replace odd Unicode bullets in PDFs to normal bullet point\n",
    "    #Replace smart quotes with normal quotes\n",
    "    text = text.replace(\"\\u2019\", \"'\") \n",
    "    text = text.replace(\"\\u201c\", '\"')\n",
    "    text = text.replace(\"\\u201d\", '\"')\n",
    "\n",
    "    return text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3298bf0e",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Multi-Column Extraction</span>\n",
    "\n",
    "##### <span style=\"color: pink\">As many pdfs use a two-column layout which might extract texts in the wrong order (e.g., reading across columns instead of down), this function would split the page into left and right columns, extract text from each separately, combine them in reading order, compare with normal extraction, and finally chooose version with higher number of texts.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "195892ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_with_columns(page):\n",
    "    width = page.width\n",
    "    height = page.height\n",
    "    mid = width / 2\n",
    "\n",
    "    # 2-column split\n",
    "    left = page.crop((0, 0, mid, height))\n",
    "    right = page.crop((mid, 0, width, height))\n",
    "\n",
    "    left_text = left.extract_text(layout=True) or \"\"\n",
    "    right_text = right.extract_text(layout=True) or \"\"\n",
    "    two_col = left_text + \"\\n\" + right_text\n",
    "\n",
    "    # 1-column extract\n",
    "    single = page.extract_text(layout=True) or \"\"\n",
    "\n",
    "    return two_col if len(two_col) > len(single) else single\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b66bf8",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">OCR Extraction</span>\n",
    "\n",
    "##### <span style=\"color: pink\">As ESG report is not text-only, Optical Character Recognition is required to work with image-embded pages. This function converts a specific PDF page into an image, runs OCR, and finally cleans the text.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a756d5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_ocr(pdf_path, page_number):\n",
    "    #Store all images into a list\n",
    "    images = convert_from_path(\n",
    "        pdf_path,\n",
    "        first_page=page_number+1,\n",
    "        last_page=page_number+1\n",
    "    )\n",
    "\n",
    "    # A page may render into multiple image tiles, so after checking if more than one images are produced for the same page, using the first image is fine.\n",
    "    img = images[0]\n",
    "    text = pytesseract.image_to_string(img)\n",
    "    return clean_text(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "56515763",
   "metadata": {},
   "outputs": [],
   "source": [
    "# with pdfplumber.open(\"input/ESG Report 2024.pdf\") as pdf:\n",
    "#     print(\"Number of pages:\", len(pdf.pages))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de13b692",
   "metadata": {},
   "outputs": [],
   "source": [
    "# #DO NOT USE: this is for testing of the previous function\n",
    "\n",
    "# def debug_pdf_images(pdf_path, page_number):\n",
    "#     images = convert_from_path(\n",
    "#         pdf_path,\n",
    "#         first_page=page_number+1,\n",
    "#         last_page=page_number+1\n",
    "#     )\n",
    "    \n",
    "#     print(f\"Page {page_number+1} produced {len(images)} image(s):\")\n",
    "#     for i, img in enumerate(images):\n",
    "#         print(f\" - Image {i}: size={img.size}\")\n",
    "\n",
    "\n",
    "# def scan_pdf_for_image_tiles(pdf_path):\n",
    "#     from pdf2image import convert_from_path\n",
    "#     import pdfplumber\n",
    "\n",
    "#     with pdfplumber.open(pdf_path) as pdf:\n",
    "#         n_pages = len(pdf.pages)\n",
    "\n",
    "#     for page_num in range(n_pages):\n",
    "#         images = convert_from_path(\n",
    "#             pdf_path,\n",
    "#             first_page=page_num+1,\n",
    "#             last_page=page_num+1\n",
    "#         )\n",
    "#         print(f\"Page {page_num+1} produced {len(images)} image(s)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "52fb076a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# debug_pdf_images(\"input/ESG Report 2024.pdf\", 0)   \n",
    "# debug_pdf_images(\"input/ESG Report 2024.pdf\", 1)  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fb813458",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# scan_pdf_for_image_tiles(\"input/ESG Report 2024.pdf\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e692fe",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Hybrid Page Extraction</span>\n",
    "\n",
    "##### <span style=\"color: pink\">ESG documents → OCR-first</span>\n",
    "##### <span style=\"color: pink\">Annual reports → pdfplumber-first</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f4606681",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_esg_file(filename):\n",
    "    name = os.path.basename(filename).lower()\n",
    "    return \"esg\" in filename.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "1af77528",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_page_hybrid(pdf_path, page, page_number, is_esg, ocr_threshold=60):\n",
    "    if is_esg:\n",
    "        # Try text extraction with columns\n",
    "        pdf_text = extract_text_with_columns(page)\n",
    "        pdf_text_clean = clean_text(pdf_text)\n",
    "        pdf_len = len(pdf_text_clean)\n",
    "\n",
    "        if pdf_len > ocr_threshold:\n",
    "            print(f\" → Page {page_number+1}: ESG: pdfplumber ({pdf_len} chars)\")\n",
    "            return pdf_text_clean\n",
    "\n",
    "        # Otherwise OCR\n",
    "        print(f\" → Page {page_number+1}: ESG: OCR fallback ({pdf_len} chars)\")\n",
    "        return extract_text_ocr(pdf_path, page_number)\n",
    "\n",
    "    else:\n",
    "        # Use single-column extraction to avoid chopping characters\n",
    "        pdf_text = page.extract_text(layout=True) or \"\"\n",
    "        pdf_text_clean = clean_text(pdf_text)\n",
    "        pdf_len = len(pdf_text_clean)\n",
    "\n",
    "        if pdf_len == 0:\n",
    "            # Only then try OCR as a last resort\n",
    "            print(f\" → Page {page_number+1}: 10-K: EMPTY → OCR fallback\")\n",
    "            return extract_text_ocr(pdf_path, page_number)\n",
    "\n",
    "        print(f\" → Page {page_number+1}: 10-K: pdfplumber only ({pdf_len} chars)\")\n",
    "        return pdf_text_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "767684d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#STILL TESTING - DO NOT USE\n",
    "def extract_page_hybrid(pdf_path, page, page_number, is_esg, ocr_threshold=60):\n",
    "    if is_esg:\n",
    "        ocr_text = extract_text_ocr(pdf_path, page_number)\n",
    "        ocr_len = len(ocr_text.strip())\n",
    "\n",
    "        if ocr_len >= ocr_threshold:\n",
    "            return ocr_text\n",
    "\n",
    "        # Fallback to pdfplumber if OCR is too weak\n",
    "        pdf_text = extract_text_with_columns(page)\n",
    "        pdf_len = len(pdf_text.strip())\n",
    "\n",
    "        return clean_text(pdf_text)\n",
    "\n",
    "    # pdf_text = extract_text_with_columns(page)\n",
    "    # pdf_len = len(pdf_text.strip())\n",
    "\n",
    "    pdf_text = page.extract_text(layout=True) or \"\"\n",
    "    pdf_text_clean = clean_text(pdf_text)\n",
    "    pdf_len = len(pdf_text_clean)\n",
    "\n",
    "    if pdf_len == 0:\n",
    "        # Only then try OCR as a last resort\n",
    "        print(f\" → Page {page_number+1}: 10-K: EMPTY → OCR fallback\")\n",
    "        return extract_text_ocr(pdf_path, page_number)\n",
    "    \n",
    "    # if pdf_len >= ocr_threshold:\n",
    "    #     return clean_text(pdf_text)\n",
    "\n",
    "    # print(f\" → Page {page_number+1}: 10-K: pdfplumber only ({pdf_len} chars)\")\n",
    "    return extract_text_ocr(pdf_path, page_number)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ec0e721",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Full Hybrid Extraction</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5de50406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_hybrid(pdf_path):\n",
    "    print(f\"\\nExtracting: {pdf_path}\")\n",
    "    full_text = \"\"\n",
    "\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        n_pages = len(pdf.pages)\n",
    "        print(f\"PDF has {n_pages} pages\")\n",
    "\n",
    "        for i, page in enumerate(pdf.pages):\n",
    "            page_text = extract_page_hybrid(pdf_path, page, i, is_esg=is_esg_file(pdf_path))\n",
    "            full_text += page_text + f\"\\n\\n--- PAGE {i+1} END ---\\n\\n\"\n",
    "\n",
    "    return full_text.strip()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40346640",
   "metadata": {},
   "source": [
    "# <span style=\"color: aquamarine;\">II. Text Chunking</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a0d229",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Chunk Text</span>\n",
    "\n",
    "#### <span style=\"color: pink\">This step is to split text into chunks of 600. Parameters include text (text to chunk), chunk_size (target words per chunk), and overlap (words to overlap between chunks).</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f17fdf18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=600, overlap=100):\n",
    "    words = text.split()\n",
    "    chunks = []\n",
    "    start = 0\n",
    "\n",
    "    while start < len(words):\n",
    "        end = start + chunk_size\n",
    "        chunk_words = words[start:end]\n",
    "        chunk = ' '.join(chunk_words)\n",
    "        chunks.append(chunk)\n",
    "        start += max(chunk_size - overlap, 1)\n",
    "\n",
    "    return chunks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e16ce0",
   "metadata": {},
   "source": [
    "### <span style=\"color: yellow\">Create Document Store</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fcc71c49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_document_store(cleaned_texts, company_name, chunk_size=600, overlap=100):\n",
    "    \n",
    "    all_chunks = []\n",
    "    chunk_counter = 1\n",
    "    \n",
    "    print(\"\\nCreating document store...\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    for source_file, text in cleaned_texts.items():\n",
    "        print(f\"\\nProcessing: {source_file}\")\n",
    "        \n",
    "        # Chunk the text\n",
    "        chunks = chunk_text(text, chunk_size=chunk_size, overlap=overlap)\n",
    "        print(f\"  Created {len(chunks)} chunks\")\n",
    "        \n",
    "        # Add each chunk to the list\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            chunk_data = {\n",
    "                'chunk_id': f\"chunk_{chunk_counter:03d}\",\n",
    "                'company': company_name,\n",
    "                'source_file': source_file,\n",
    "                'chunk_text': chunk\n",
    "            }\n",
    "            all_chunks.append(chunk_data)\n",
    "            chunk_counter += 1\n",
    "    \n",
    "    df = pd.DataFrame(all_chunks)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"✓ Document store created!\")\n",
    "    print(f\"  Total chunks: {len(df)}\")\n",
    "    print(f\"  Total documents: {len(cleaned_texts)}\")\n",
    "    print(\"=\"*60)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "def43abf",
   "metadata": {},
   "source": [
    "# <span style=\"color: aquamarine;\">III. Run Extraction → Cleaning → Chunking</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c45cf050",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "Processing annual_report_2024\n",
      "============================================================\n",
      "\n",
      "Extracting: input/10K Report 2024.pdf\n",
      "PDF has 104 pages\n",
      " → Page 1: 10-K: pdfplumber only (4306 chars)\n",
      " → Page 2: 10-K: pdfplumber only (1533 chars)\n",
      " → Page 3: 10-K: pdfplumber only (265 chars)\n",
      " → Page 4: 10-K: pdfplumber only (1225 chars)\n",
      " → Page 5: 10-K: pdfplumber only (3530 chars)\n",
      " → Page 6: 10-K: pdfplumber only (4745 chars)\n",
      " → Page 7: 10-K: pdfplumber only (4184 chars)\n",
      " → Page 8: 10-K: pdfplumber only (4378 chars)\n",
      " → Page 9: 10-K: pdfplumber only (3478 chars)\n",
      " → Page 10: 10-K: pdfplumber only (4935 chars)\n",
      " → Page 11: 10-K: pdfplumber only (4039 chars)\n",
      " → Page 12: 10-K: pdfplumber only (4545 chars)\n",
      " → Page 13: 10-K: pdfplumber only (4123 chars)\n",
      " → Page 14: 10-K: pdfplumber only (5429 chars)\n",
      " → Page 15: 10-K: pdfplumber only (5214 chars)\n",
      " → Page 16: 10-K: pdfplumber only (6159 chars)\n",
      " → Page 17: 10-K: pdfplumber only (4673 chars)\n",
      " → Page 18: 10-K: pdfplumber only (5154 chars)\n",
      " → Page 19: 10-K: pdfplumber only (717 chars)\n",
      " → Page 20: 10-K: pdfplumber only (4681 chars)\n",
      " → Page 21: 10-K: pdfplumber only (5559 chars)\n",
      " → Page 22: 10-K: pdfplumber only (4956 chars)\n",
      " → Page 23: 10-K: pdfplumber only (6108 chars)\n",
      " → Page 24: 10-K: pdfplumber only (5159 chars)\n",
      " → Page 25: 10-K: pdfplumber only (2311 chars)\n",
      " → Page 26: 10-K: pdfplumber only (4608 chars)\n",
      " → Page 27: 10-K: pdfplumber only (5380 chars)\n",
      " → Page 28: 10-K: pdfplumber only (5647 chars)\n",
      " → Page 29: 10-K: pdfplumber only (5725 chars)\n",
      " → Page 30: 10-K: pdfplumber only (5062 chars)\n",
      " → Page 31: 10-K: pdfplumber only (2818 chars)\n",
      " → Page 32: 10-K: pdfplumber only (1915 chars)\n",
      " → Page 33: 10-K: pdfplumber only (3251 chars)\n",
      " → Page 34: 10-K: pdfplumber only (1086 chars)\n",
      " → Page 35: 10-K: pdfplumber only (1661 chars)\n",
      " → Page 36: 10-K: pdfplumber only (1293 chars)\n",
      " → Page 37: 10-K: pdfplumber only (5492 chars)\n",
      " → Page 38: 10-K: pdfplumber only (2664 chars)\n",
      " → Page 39: 10-K: pdfplumber only (3058 chars)\n",
      " → Page 40: 10-K: pdfplumber only (3621 chars)\n",
      " → Page 41: 10-K: pdfplumber only (4440 chars)\n",
      " → Page 42: 10-K: pdfplumber only (3558 chars)\n",
      " → Page 43: 10-K: pdfplumber only (5041 chars)\n",
      " → Page 44: 10-K: pdfplumber only (4924 chars)\n",
      " → Page 45: 10-K: pdfplumber only (4471 chars)\n",
      " → Page 46: 10-K: pdfplumber only (5341 chars)\n",
      " → Page 47: 10-K: pdfplumber only (5039 chars)\n",
      " → Page 48: 10-K: pdfplumber only (5524 chars)\n",
      " → Page 49: 10-K: pdfplumber only (4402 chars)\n",
      " → Page 50: 10-K: pdfplumber only (3503 chars)\n",
      " → Page 51: 10-K: pdfplumber only (1573 chars)\n",
      " → Page 52: 10-K: pdfplumber only (1632 chars)\n",
      " → Page 53: 10-K: pdfplumber only (2068 chars)\n",
      " → Page 54: 10-K: pdfplumber only (4374 chars)\n",
      " → Page 55: 10-K: pdfplumber only (1307 chars)\n",
      " → Page 56: 10-K: pdfplumber only (4227 chars)\n",
      " → Page 57: 10-K: pdfplumber only (3733 chars)\n",
      " → Page 58: 10-K: pdfplumber only (2376 chars)\n",
      " → Page 59: 10-K: pdfplumber only (1718 chars)\n",
      " → Page 60: 10-K: pdfplumber only (544 chars)\n",
      " → Page 61: 10-K: pdfplumber only (2456 chars)\n",
      " → Page 62: 10-K: pdfplumber only (1565 chars)\n",
      " → Page 63: 10-K: pdfplumber only (3793 chars)\n",
      " → Page 64: 10-K: pdfplumber only (3956 chars)\n",
      " → Page 65: 10-K: pdfplumber only (4405 chars)\n",
      " → Page 66: 10-K: pdfplumber only (3409 chars)\n",
      " → Page 67: 10-K: pdfplumber only (4761 chars)\n",
      " → Page 68: 10-K: pdfplumber only (4063 chars)\n",
      " → Page 69: 10-K: pdfplumber only (3196 chars)\n",
      " → Page 70: 10-K: pdfplumber only (3392 chars)\n",
      " → Page 71: 10-K: pdfplumber only (4668 chars)\n",
      " → Page 72: 10-K: pdfplumber only (4482 chars)\n",
      " → Page 73: 10-K: pdfplumber only (3468 chars)\n",
      " → Page 74: 10-K: pdfplumber only (2961 chars)\n",
      " → Page 75: 10-K: pdfplumber only (3526 chars)\n",
      " → Page 76: 10-K: pdfplumber only (4295 chars)\n",
      " → Page 77: 10-K: pdfplumber only (2268 chars)\n",
      " → Page 78: 10-K: pdfplumber only (3070 chars)\n",
      " → Page 79: 10-K: pdfplumber only (4470 chars)\n",
      " → Page 80: 10-K: pdfplumber only (2608 chars)\n",
      " → Page 81: 10-K: pdfplumber only (3575 chars)\n",
      " → Page 82: 10-K: pdfplumber only (3466 chars)\n",
      " → Page 83: 10-K: pdfplumber only (4659 chars)\n",
      " → Page 84: 10-K: pdfplumber only (3178 chars)\n",
      " → Page 85: 10-K: pdfplumber only (2539 chars)\n",
      " → Page 86: 10-K: pdfplumber only (3957 chars)\n",
      " → Page 87: 10-K: pdfplumber only (2265 chars)\n",
      " → Page 88: 10-K: pdfplumber only (2212 chars)\n",
      " → Page 89: 10-K: pdfplumber only (3064 chars)\n",
      " → Page 90: 10-K: pdfplumber only (3993 chars)\n",
      " → Page 91: 10-K: pdfplumber only (3407 chars)\n",
      " → Page 92: 10-K: pdfplumber only (4429 chars)\n",
      " → Page 93: 10-K: pdfplumber only (2394 chars)\n",
      " → Page 94: 10-K: pdfplumber only (1855 chars)\n",
      " → Page 95: 10-K: pdfplumber only (2977 chars)\n",
      " → Page 96: 10-K: pdfplumber only (4016 chars)\n",
      " → Page 97: 10-K: pdfplumber only (3885 chars)\n",
      " → Page 98: 10-K: pdfplumber only (3776 chars)\n",
      " → Page 99: 10-K: pdfplumber only (3917 chars)\n",
      " → Page 100: 10-K: pdfplumber only (4537 chars)\n",
      " → Page 101: 10-K: pdfplumber only (3052 chars)\n",
      " → Page 102: 10-K: pdfplumber only (92 chars)\n",
      " → Page 103: 10-K: pdfplumber only (404 chars)\n",
      " → Page 104: 10-K: pdfplumber only (1296 chars)\n",
      "✓ Saved cleaned text: output/annual_report_2024_clean.txt\n",
      "\n",
      "============================================================\n",
      "Processing esg_report_2024\n",
      "============================================================\n",
      "\n",
      "Extracting: input/ESG Report 2024.pdf\n",
      "PDF has 59 pages\n",
      "✓ Saved cleaned text: output/esg_report_2024_clean.txt\n",
      "\n",
      "============================================================\n",
      "Processing major_holders\n",
      "============================================================\n",
      "\n",
      "Extracting: input/Major Holders Summary.pdf\n",
      "PDF has 2 pages\n",
      " → Page 1: 10-K: pdfplumber only (1605 chars)\n",
      " → Page 2: 10-K: pdfplumber only (1562 chars)\n",
      "✓ Saved cleaned text: output/major_holders_clean.txt\n"
     ]
    }
   ],
   "source": [
    "cleaned_texts = {}\n",
    "\n",
    "for name, path in input_files.items():\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"Processing {name}\")\n",
    "    print(\"=\"*60)\n",
    "\n",
    "    raw = extract_text_hybrid(path)\n",
    "    cleaned = clean_text(raw)\n",
    "\n",
    "    cleaned_texts[name] = cleaned\n",
    "\n",
    "    outpath = f\"output/{name}_clean.txt\"\n",
    "    with open(outpath, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(cleaned)\n",
    "    print(f\"✓ Saved cleaned text: {outpath}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "542ed78c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Creating document store...\n",
      "============================================================\n",
      "\n",
      "Processing: annual_report_2024\n",
      "  Created 112 chunks\n",
      "\n",
      "Processing: esg_report_2024\n",
      "  Created 46 chunks\n",
      "\n",
      "Processing: major_holders\n",
      "  Created 1 chunks\n",
      "\n",
      "============================================================\n",
      "✓ Document store created!\n",
      "  Total chunks: 159\n",
      "  Total documents: 3\n",
      "============================================================\n",
      "\n",
      "✓ Saved chunks → data/delta/chunks.csv\n"
     ]
    }
   ],
   "source": [
    "document_store = create_document_store(\n",
    "    cleaned_texts,\n",
    "    company_name=company_name,\n",
    "    chunk_size=600,\n",
    "    overlap=100\n",
    ")\n",
    "\n",
    "document_store[\"word_count\"] = document_store[\"chunk_text\"].str.split().str.len()\n",
    "\n",
    "csv_path = f\"data/{company_name}/chunks.csv\"\n",
    "document_store.to_csv(csv_path, index=False)\n",
    "print(f\"\\n✓ Saved chunks → {csv_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5a6acf47",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chunk_id</th>\n",
       "      <th>company</th>\n",
       "      <th>source_file</th>\n",
       "      <th>chunk_text</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>chunk_001</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 FORM 10-K ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 iS} For the fiscal year ended...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chunk_002</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>statements of the registrant included in the filing reflect the correction of an error to previously issued financial statements 0 Indicate by check mark whether any of those error corrections are...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>chunk_003</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>actual results to differ materially from historical experience or our present expectations. Known material risk factors applicable to Delta are described in \"Risk Factors Relating to Delta\" and \"R...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>chunk_004</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>six continents. Our domestic network is centered around core hubs in Atlanta, Detroit, Minneapolis-St. Paul and Salt Lake City. Core hubs have strong local passenger share, a high penetration of c...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chunk_005</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>consumer brand, including: + Recognized as the 2024 Airline of the Year by aviation publication Air Transport World. + Named Best U.S. Airline and topped five categories in the Forbes Travel Guide...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>chunk_006</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>mileage credits (\"miles\") when traveling on Delta, Delta Connection and our partner airlines. Miles may also be earned by using certain services offered by program partners, such as credit card, r...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>chunk_007</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>Consolidated Financial Statements for additional information about our equity investments. Each of our joint venture or cooperation arrangements provides for joint commercial cooperation with the ...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chunk_008</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>the other member airlines, providing opportunities to increase connecting traffic while offering enhanced customer service through reciprocal codesharing and loyalty program participation, airport...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>chunk_009</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>from around the world. With agreements to service multiple next-generation aircraft engines, Delta TechOps is positioned as a leading global service provider for state-of-the-art, more sustainable...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>chunk_010</td>\n",
       "      <td>delta</td>\n",
       "      <td>annual_report_2024</td>\n",
       "      <td>work with airport partners to drive fuel savings by limiting the use of aircraft Auxiliary Power Units (\"APUs\") during ground operations. In 2024, we installed 30 new preconditioned air units at o...</td>\n",
       "      <td>600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    chunk_id company         source_file  \\\n",
       "0  chunk_001   delta  annual_report_2024   \n",
       "1  chunk_002   delta  annual_report_2024   \n",
       "2  chunk_003   delta  annual_report_2024   \n",
       "3  chunk_004   delta  annual_report_2024   \n",
       "4  chunk_005   delta  annual_report_2024   \n",
       "5  chunk_006   delta  annual_report_2024   \n",
       "6  chunk_007   delta  annual_report_2024   \n",
       "7  chunk_008   delta  annual_report_2024   \n",
       "8  chunk_009   delta  annual_report_2024   \n",
       "9  chunk_010   delta  annual_report_2024   \n",
       "\n",
       "                                                                                                                                                                                                chunk_text  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSION Washington, D.C. 20549 FORM 10-K ANNUAL REPORT PURSUANT TO SECTION 13 OR 15(d) OF THE SECURITIES EXCHANGE ACT OF 1934 iS} For the fiscal year ended...   \n",
       "1  statements of the registrant included in the filing reflect the correction of an error to previously issued financial statements 0 Indicate by check mark whether any of those error corrections are...   \n",
       "2  actual results to differ materially from historical experience or our present expectations. Known material risk factors applicable to Delta are described in \"Risk Factors Relating to Delta\" and \"R...   \n",
       "3  six continents. Our domestic network is centered around core hubs in Atlanta, Detroit, Minneapolis-St. Paul and Salt Lake City. Core hubs have strong local passenger share, a high penetration of c...   \n",
       "4  consumer brand, including: + Recognized as the 2024 Airline of the Year by aviation publication Air Transport World. + Named Best U.S. Airline and topped five categories in the Forbes Travel Guide...   \n",
       "5  mileage credits (\"miles\") when traveling on Delta, Delta Connection and our partner airlines. Miles may also be earned by using certain services offered by program partners, such as credit card, r...   \n",
       "6  Consolidated Financial Statements for additional information about our equity investments. Each of our joint venture or cooperation arrangements provides for joint commercial cooperation with the ...   \n",
       "7  the other member airlines, providing opportunities to increase connecting traffic while offering enhanced customer service through reciprocal codesharing and loyalty program participation, airport...   \n",
       "8  from around the world. With agreements to service multiple next-generation aircraft engines, Delta TechOps is positioned as a leading global service provider for state-of-the-art, more sustainable...   \n",
       "9  work with airport partners to drive fuel savings by limiting the use of aircraft Auxiliary Power Units (\"APUs\") during ground operations. In 2024, we installed 30 new preconditioned air units at o...   \n",
       "\n",
       "   word_count  \n",
       "0         600  \n",
       "1         600  \n",
       "2         600  \n",
       "3         600  \n",
       "4         600  \n",
       "5         600  \n",
       "6         600  \n",
       "7         600  \n",
       "8         600  \n",
       "9         600  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "document_store.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbc1a8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
